{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-02T13:57:54.470910Z",
     "start_time": "2025-04-02T13:57:50.203465Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import contractions\n",
    "import torch\n",
    "import unidecode\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "import cupy as cp\n",
    "\n",
    "# Forceer het vrijmaken van geheugen\n",
    "cp.get_default_memory_pool().free_all_blocks()"
   ],
   "id": "3d9aca4522fd2098",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import spacy\n",
    "from gliner_spacy.pipeline import GlinerSpacy\n",
    "from thinc.api import set_gpu_allocator, require_gpu\n",
    "from unidecode import unidecode\n",
    "import contractions\n",
    "\n",
    "# Controleer of GPU beschikbaar is\n",
    "if torch.cuda.is_available():\n",
    "    set_gpu_allocator(\"pytorch\")\n",
    "    require_gpu(0)\n",
    "    device = \"cuda\"\n",
    "    print(\"GPU wordt gebruikt!\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"CPU wordt gebruikt\")\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Laad Nederlandse en Engelse SpaCy-modellen\n",
    "print(\"Laad Nederlandse en Engelse SpaCy-modellen...\")\n",
    "nl_model = spacy.load('nl_core_news_sm')\n",
    "en_model = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Configuratie voor GLiNER\n",
    "custom_spacy_config = {\n",
    "    \"gliner_model\": \"urchade/gliner_mediumv2.1\",\n",
    "    \"chunk_size\": 250,\n",
    "    \"labels\": [\"persoon\", \"datum\", \"organisatie\", \"gebeurtenis\"],\n",
    "    \"style\": \"ent\",\n",
    "    \"threshold\": 0.4,\n",
    "    \"map_location\": device\n",
    "}\n",
    "\n",
    "# Voeg de GLiNER pipe toe aan de modellen\n",
    "nl_model.add_pipe('gliner_spacy', last=True, config=custom_spacy_config)\n",
    "en_model.add_pipe('gliner_spacy', last=True, config=custom_spacy_config)\n",
    "\n",
    "# CSV-bestanden\n",
    "csv_path = '/home/nena-meijer/PyCharmMiscProject/dataset/VWS_subset/4-VWS_documents_no_empties.csv'\n",
    "output_csv_path = '/home/nena-meijer/PyCharmMiscProject/dataset/VWS_subset/5-VWS_documents_NER_nl_labels.csv'\n",
    "\n",
    "test_mode = False  # Zet op False om de hele dataset te verwerken\n",
    "num_test_rows = 10  # Aantal rijen in testmodus\n",
    "chunksize = 300 if not test_mode else num_test_rows\n",
    "\n",
    "df_result = pd.DataFrame()\n",
    "\n",
    "excluded_persons = {\"ik\", \"je\", \"jij\", \"u\", \"wij\", \"we\", \"zij\", \"hij\", \"haar\", \"hem\", \"hun\", \"mij\", \"me\", \"jou\", \"jullie\", \"your\", \"you\", \"his\", \"her\", \"they\", \"them\"}\n",
    "def filter_entities(persons):\n",
    "    \"\"\"Verwijder ongewenste woorden uit de lijst met 'persons'-entiteiten.\"\"\"\n",
    "    return [p for p in persons if p.lower() not in excluded_persons]\n",
    "\n",
    "def extract_entities(text, lang):\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return [], [], [], [], []\n",
    "\n",
    "    nlp_model = nl_model if lang == 'nl' else en_model\n",
    "\n",
    "    if 'gliner_spacy' not in nlp_model.pipe_names:\n",
    "        print(\"⚠️ GLiNER niet meer in pipeline! Model herinitialiseren...\")\n",
    "        nlp_model.add_pipe('gliner_spacy', last=True, config=custom_spacy_config)\n",
    "\n",
    "    doc = nlp_model(text)\n",
    "\n",
    "    persons = [ent.text for ent in doc.ents if ent.label_ == 'persoon']\n",
    "    dates = [ent.text for ent in doc.ents if ent.label_ == 'datum']\n",
    "    organisations = [ent.text for ent in doc.ents if ent.label_ == 'organisatie']\n",
    "    events = [ent.text for ent in doc.ents if ent.label_ == 'gebeurtenis']\n",
    "\n",
    "    del doc\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    persons = filter_entities(persons)\n",
    "\n",
    "    return persons, dates, organisations, events\n",
    "\n",
    "for batch_num, chunk in enumerate(pd.read_csv(csv_path, chunksize=chunksize), 1):\n",
    "    print(f\"\\nVerwerken van batch {batch_num}...\")\n",
    "    result = []\n",
    "\n",
    "    chunk.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    if 'document_text' not in chunk.columns or 'document_language' not in chunk.columns:\n",
    "        raise KeyError(\"De vereiste kolommen 'document_text' of 'document_language' ontbreken in de dataset.\")\n",
    "\n",
    "    for idx, row in chunk.iterrows():\n",
    "        if idx % 100 == 0:\n",
    "            print(f\"Verwerkte {idx} rijen van de batch.\")\n",
    "\n",
    "        try:\n",
    "            document_text = str(row['document_text'])\n",
    "            document_text = contractions.fix(unidecode(row['document_text'])).strip().replace('\\n', '')\n",
    "            entities = extract_entities(document_text, row['document_language'])\n",
    "            result.append(entities)\n",
    "        except Exception as e:\n",
    "            print(f\"Fout bij rij {idx}, {document_text}: {e}\")\n",
    "            raise\n",
    "\n",
    "    chunk[['NER_persons', 'NER_dates', 'NER_orgs', 'NER_events']] = pd.DataFrame(result, columns=['NER_persons', 'NER_dates', 'NER_orgs', 'NER_events'])\n",
    "\n",
    "    if test_mode:\n",
    "        display(chunk[['NER_persons', 'NER_dates', 'NER_orgs', 'NER_events']])\n",
    "        break  # Stop na de testbatch\n",
    "\n",
    "    chunk.to_csv(f\"/home/nena-meijer/PyCharmMiscProject/dataset/VWS_subset/NER_batches/NER_batch_{batch_num}.csv\", index=False)\n",
    "    df_result.to_csv(output_csv_path, index=False)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "print(\"\\nVerwerking voltooid.\")\n"
   ],
   "id": "fb548254c1074da0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# gliner test\n",
    "\n",
    "import spacy\n",
    "from gliner_spacy.pipeline import GlinerSpacy\n",
    "\n",
    "nlp = spacy.load('nl_core_news_lg')\n",
    "nlp.add_pipe(\"gliner_spacy\")\n",
    "text = \"611783 ee iow: @minvws.nl from: } sent: tue 10/26/2021 8:13:10 am subject: re: conceptartikel voor vws#net over wobverzoeken corona received: tue 10/26/2021 8:13:11 am hoi allen, eere verwerkt de opmerkingen van eee in het voorliggende hoevertelikhetthuisinterview en verwijst alvast naar vws#dianovember, waarin we een achtergrondartikel plaatsen over de nieuwe programmadirectie met 0.a. antwoord op de vragen die [&gY=erecht stelt. later deze week stort ich op dat vws#diaartikel ik stuur jullie begin van de middag de 'eindversie' van het huidige vws#netinterview zodat jullie er een laatste (goedkeurende) blik op kunnen werpen. het streven is om dit in de loop van de middag te publiceren op vws#net. iedereen happy zo? met vriendelijke groet, 5.1.2e parnassusplein 5 | 2511 vx | den haag | kamer postbus 20350 | 2500 ej | den haag t070 minvws.nt http://www. rijksoverhe nl nederland gezond en wel. dubbel 611783 611783\"\n",
    "\n",
    "doc = nlp(text)\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, '-->', ent.label_)\n"
   ],
   "id": "7ca478e90e81374e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# NER BERTje/BERT\n",
    "\n",
    "import pandas as pd\n",
    "from transformers import pipeline\n",
    "\n",
    "# Laad de pipeline voor NER met BERT (Nederlands en Engels)\n",
    "nl_ner_pipeline = pipeline(\"ner\", model=\"GroNLP/bert-base-dutch-cased\")\n",
    "en_ner_pipeline = pipeline(\"ner\", model=\"dbmdz/bert-large-cased-finetuned-conll03-english\")\n",
    "\n",
    "# Laad de CSV met de documenttekst\n",
    "csv_path = '/home/nena-meijer/PyCharmMiscProject/dataset/VWS/8-VWS_documents_normalized-FINAL.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Functie om NER uit te voeren en datums en namen te extraheren\n",
    "def extract_dates_and_names(text, lang):\n",
    "    if not isinstance(text, str):  # Controleer of de tekst geldig is\n",
    "        return \"\", \"\"  # Geen datums of namen\n",
    "\n",
    "    # Kies het juiste model op basis van de taal\n",
    "    ner_pipeline = nl_ner_pipeline if lang == 'nl' else en_ner_pipeline\n",
    "\n",
    "    # Pipeline om NER uit te voeren\n",
    "    ner_results = ner_pipeline(text)\n",
    "\n",
    "    print(f\"NER results for text: {ner_results}\")  # Voeg deze regel toe om te kijken naar de resultaten\n",
    "\n",
    "    # Filter voor datums en namen\n",
    "    dates = []\n",
    "    names = []\n",
    "\n",
    "    for entity in ner_results:\n",
    "        if entity['entity'] == 'B-DATE' or entity['entity'] == 'I-DATE':\n",
    "            dates.append(entity['word'])\n",
    "        if entity['entity'] == 'B-PER' or entity['entity'] == 'I-PER':\n",
    "            names.append(entity['word'])\n",
    "\n",
    "    # Zet de datums en namen om naar een enkele string gescheiden door een puntkomma\n",
    "    dates_str = \"; \".join(dates)\n",
    "    names_str = \"; \".join(names)\n",
    "\n",
    "    return dates_str, names_str\n",
    "\n",
    "\n",
    "# Verwerk alleen de eerste 10 rijen\n",
    "df_subset = df.iloc[:10].copy()  # Kopie maken om de originele dataframe niet te overschrijven\n",
    "df_subset['NER_dates'], df_subset['NER_names'] = zip(*df_subset.apply(lambda row: extract_dates_and_names(row['document_text'], row['document_language']), axis=1))\n",
    "\n",
    "# Bekijk de resultaten\n",
    "df_subset[['document_text', 'NER_dates', 'NER_names']]\n"
   ],
   "id": "1719cd861a943b5a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# datums regex\n",
    "\n",
    "import pandas as pd\n",
    "import re\n",
    "import dateparser\n",
    "\n",
    "# Laad de CSV met de documenttekst\n",
    "csv_path = '/home/nena-meijer/PyCharmMiscProject/dataset/VWS/9-VWS_documents_with_ministries.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Reguliere expressies voor extra datumformaten\n",
    "date_patterns = [\n",
    "    r'\\b\\d{1,2}/\\d{1,2}/\\d{4}\\b',         # 26/4/2020, 04/26/2020\n",
    "    r'\\b\\d{1,2}-\\d{1,2}-\\d{4}\\b',         # 26-4-2020, 04-26-2020\n",
    "    r'\\b\\d{4}/\\d{1,2}/\\d{1,2}\\b',         # 2020/04/26\n",
    "    r'\\b\\d{4}-\\d{1,2}-\\d{1,2}\\b',         # 2020-04-26\n",
    "    r'\\b\\d{1,2} [a-zA-Zé]+\\.* \\d{4}\\b',   # 26 april 2020, 26 apr. 2020, 26 Apr. 2020\n",
    "    r'\\b[a-zA-Zé]+ \\d{1,2}, \\d{4}\\b',     # April 26, 2020 (Engelse volgorde)\n",
    "    r'\\b\\d{1,2}(?:e|ste)? [a-zA-Zé]+ \\d{4}\\b',  # 26e april 2020, 26ste april 2020\n",
    "]\n",
    "\n",
    "def extract_dates_with_regex(text):\n",
    "    dates = []\n",
    "    for pattern in date_patterns:\n",
    "        matches = re.findall(pattern, text)\n",
    "        dates.extend(matches)\n",
    "    return dates\n",
    "\n",
    "def normalize_date(date_str):\n",
    "    # Probeer eerst de Engelse datuminstelling voor MM/DD/YYYY (MDY)\n",
    "    parsed_date = dateparser.parse(date_str, languages=['en'], settings={'DATE_ORDER': 'MDY'})\n",
    "\n",
    "    # Als dat niet werkt, probeer de Nederlandse instelling voor DD/MM/YYYY (DMY)\n",
    "    if not parsed_date:\n",
    "        parsed_date = dateparser.parse(date_str, languages=['nl'], settings={'DATE_ORDER': 'DMY'})\n",
    "\n",
    "    # Controleer of de datum geldig is en het jaartal in het juiste bereik valt\n",
    "    if parsed_date and 2010 <= parsed_date.year < 2030:\n",
    "        return parsed_date.strftime('%Y-%m-%d')\n",
    "    return None\n",
    "\n",
    "def extract_dates_with_regex_only(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    regex_dates = extract_dates_with_regex(text)\n",
    "\n",
    "    seen_dates = set()\n",
    "    all_dates = []\n",
    "\n",
    "    for date in regex_dates:\n",
    "        normalized_date = normalize_date(date)\n",
    "        if normalized_date and normalized_date not in seen_dates:\n",
    "            seen_dates.add(normalized_date)\n",
    "            all_dates.append(normalized_date)\n",
    "\n",
    "    return \"; \".join(all_dates)\n",
    "\n",
    "# Verwerk de volledige DataFrame met alleen regex\n",
    "df['NER_dates'] = df['document_text'].apply(extract_dates_with_regex_only)\n",
    "\n",
    "# Sla de resultaten op in een nieuwe CSV\n",
    "output_csv_path = '/dataset/VWS/9-VWS_documents_dates&mins_regex.csv'\n",
    "df.to_csv(output_csv_path, index=False)\n",
    "\n",
    "# Optioneel: Bekijk de eerste paar rijen van het resultaat\n",
    "df[['document_text', 'NER_dates']].head()\n"
   ],
   "id": "e6675b830fa5ee0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# precision datums regex\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Laad de CSV in\n",
    "df = pd.read_csv(\"/dataset/VWS/9-VWS_documents_dates&mins_regex.csv\")\n",
    "\n",
    "# Zorg ervoor dat de kolom NER_dates wordt omgezet naar een lijst van datums\n",
    "df[\"NER_dates\"] = df[\"NER_dates\"].apply(lambda x: x.split(\";\") if isinstance(x, str) else [])\n",
    "\n",
    "# Precision: Hoe vaak is de eerste NER-date gelijk aan document_date?\n",
    "df[\"first_match\"] = df.apply(lambda row: row[\"NER_dates\"][0] == row[\"document_date\"] if row[\"NER_dates\"] else False, axis=1)\n",
    "precision = df[\"first_match\"].mean()\n",
    "\n",
    "# Algemene aanwezigheid: Hoe vaak komt document_date ergens in NER_dates voor?\n",
    "df[\"any_match\"] = df.apply(lambda row: row[\"document_date\"] in row[\"NER_dates\"] if row[\"NER_dates\"] else False, axis=1)\n",
    "general_presence = df[\"any_match\"].mean()\n",
    "\n",
    "print(f\"Precision (eerste datum matcht): {precision:.2%}\")\n",
    "print(f\"Algemene aanwezigheid (document_date komt ergens voor): {general_presence:.2%}\")\n"
   ],
   "id": "4b39ff1d8fc4bcd4",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
